{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advantage Actor Critic (A2C)\n",
    "\n",
    "-----------\n",
    "### 0. Background: From Only Actor/Critic to Actor-Critic\n",
    "\n",
    "In [REINFORCE](../../policy-based/policy-gradient-methods/improved-reinforce/improved_reinforce.ipynb) method, we have\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta U(\\theta) \\approx \\hat{g} = \\mathbb{E}_{\\tau \\sim P(\\tau; \\theta)} \\left[ \\sum_{t=0}^T \\nabla_{\\theta} \\log \\pi_{\\theta}(a_t | s_t) \\cdot R_t^{\\text{future}} \\right]\n",
    "$$\n",
    "\n",
    "and now we consider discount factor\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta U(\\theta) \\approx \\hat{g} = \\mathbb{E}_{\\tau \\sim P(\\tau; \\theta)} \\left[ \\sum_{t=0}^T \\nabla_{\\theta} \\log \\pi_{\\theta}(a_t | s_t) \\cdot \\gamma^{t} R_t^{\\text{future}} \\right]\n",
    "$$\n",
    "\n",
    "and convert into below form, we make $G_t = \\gamma^{t} R_t^{\\text{future}}$\n",
    "$$\n",
    "\\nabla_\\theta U(\\theta) \\approx \\hat{g} = \\mathbb{E}_{\\tau \\sim P(\\tau; \\theta)} \\left[ \\sum_{t=0}^T \\nabla_{\\theta} \\log \\pi_{\\theta}(a_t | s_t) \\cdot G_t \\right]\n",
    "$$\n",
    "\n",
    "in REINFORCE like method, we use actual observed trajectory to compute $G_t$, however, we need to collect whole trajectory for  policy gradient $\\hat{g}$.\n",
    "\n",
    "$$\n",
    "G_t = r_t + \\gamma G_{t+1}\n",
    "$$\n",
    "\n",
    "in Actor-Critic method, like [SARSA](../../../model-free-learning/discrete-state-problems/temporal-difference-methods/temporal_difference_blackjack.ipynb) we take a action $a_{t+1}$ at $s_{t+1}$ but not to interact with environment and compute $G_t = r_t + \\gamma Q(s_{t+1}, a_{t+1})$, here we use **Value Network** to approximate $G_{t+1}$, so we have\n",
    "\n",
    "$$\n",
    "G_t = r_t + \\gamma V(s_{t+1}; \\theta)\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta U(\\theta) \\approx \\hat{g} = \\mathbb{E}_{\\tau \\sim P(\\tau; \\theta)} \\left[ \\sum_{t=0}^T \\nabla_{\\theta} \\log \\pi_{\\theta}(a_t | s_t) \\cdot G_t \\right]\n",
    "$$\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import the Necessary Packages\n",
    "\n",
    "In this notebook, we will implement A2C and train a policy to play [atari-pong](https://ale.farama.org/environments/pong/), using only the pixels as input. We will use convolutional neural nets, multiprocessing, and pytorch to implement and train our policy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device:  mps\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from enum import Enum\n",
    "import ale_py\n",
    "import gymnasium as gym\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from parallel_env import ParallelEnv\n",
    "from plot_utils import display_frame, save_animation, plot_scores\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "gym.register_envs(ale_py)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \n",
    "\t\t\t\t\t  \"mps\" if torch.backends.mps.is_available() else \n",
    "\t\t\t\t\t  \"cpu\")\n",
    "print(\"using device: \",device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Explore Environment\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "\t\t<img src=\"./images/pong.gif\" alt=\"Mountain Car Environment\" width=\"10%\">\n",
    "</div>\n",
    "\n",
    "#### Continuous State Space\n",
    "- **Observation Type**: `\"rgb\"`\n",
    "- **Observation Space**: `Box(0, 255, (210, 160, 3), np.uint8)`\n",
    "\t- Observations are RGB images with dimensions 210x160 and 3 color channels. The pixel values range from 0 to 255.\n",
    "\n",
    "#### Discrete Action Space\n",
    "- **Type**: `Discrete(6)`\n",
    "- **Actions**:\n",
    "\t- `0`: `NOOP` (No operation)\n",
    "\t- `1`: `FIRE`\n",
    "\t- `2`: `RIGHT`\n",
    "\t- `3`: `LEFT`\n",
    "\t- `4`: `RIGHTFIRE`\n",
    "\t- `5`: `LEFTFIRE`\n",
    "\n",
    "> To simplify training, we will only use the following two actions:\n",
    "> - `4`: `RIGHTFIRE`\n",
    "> - `5`: `LEFTFIRE`\n",
    "\n",
    "The `FIRE` part ensures the game starts again after losing a life.\n",
    "\n",
    "#### Other Settings\n",
    "1. **Frameskip**\n",
    "\t\t- **Value**: `4`\n",
    "\t\t- **Explanation**: The environment executes the same action for 4 consecutive frames before observing the next state. This deterministic frameskip makes the environment faster to train compared to the vanilla `Pong-v4`, which uses a stochastic frameskip of `(2, 5)`.\n",
    "\n",
    "2. **Repeat Action Probability**\n",
    "\t\t- **Value**: `0.0`\n",
    "\t\t- **Explanation**: This setting ensures no randomness in action repetition. The same action will always have the same effect, making the environment fully deterministic and predictable.\n",
    "\n",
    "By using deterministic frameskip and disabling action stickiness, `PongDeterministic-v4` is more efficient for training reinforcement learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.10.1+6a7e0ae)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('PongDeterministic-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State space:\n",
      " Box(0, 255, (210, 160, 3), uint8)\n",
      "Action space:\n",
      " Discrete(6)\n",
      "--------------------------------------------------\n",
      "Shape of State space 2 samples:\n",
      "[(210, 160, 3), (210, 160, 3)]\n",
      "Action space 2 samples:\n",
      "[5 2]\n"
     ]
    }
   ],
   "source": [
    "# Explore state (observation) space\n",
    "print(\"State space:\\n\", env.observation_space)\n",
    "\n",
    "# Explore action space\n",
    "print(\"Action space:\\n\", env.action_space)\n",
    "\n",
    "print(\"-\"*50)\n",
    "# Generate some samples from the state space \n",
    "print(\"Shape of State space 2 samples:\")\n",
    "print([env.observation_space.sample().shape for _ in range(2)])\n",
    "\n",
    "# Generate some samples from the action space\n",
    "print(\"Action space 2 samples:\")\n",
    "print(np.array([env.action_space.sample() for i in range(2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action(Enum):\n",
    "\tNOOP = 0         # No operation\n",
    "\tFIRE = 1         # Fire\n",
    "\tRIGHT = 2        # Move right\n",
    "\tLEFT = 3         # Move left\n",
    "\tRIGHTFIRE = 4    # Move right and fire\n",
    "\tLEFTFIRE = 5     # Move left and fire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocessing\n",
    "\n",
    "To speed up training, we can simplify the input by cropping the images and use every other pixel\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "\t<img src=\"./images/preprocess.png\" alt=\"Mountain Car Environment\" width=\"50%\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, bkg_color=np.array([144, 72, 17])):\n",
    "\t\"\"\"\n",
    "\tPreprocess a single game frame by cropping, downsampling, and normalizing.\n",
    "\n",
    "\tArgs:\n",
    "\t\timage (np.ndarray): The input image (game frame) as a NumPy array.\n",
    "\t\tbkg_color (np.ndarray): The RGB background color to subtract.\n",
    "\n",
    "\tReturns:\n",
    "\t\tnp.ndarray: The processed image, normalized to [0, 1].\n",
    "\t\"\"\"\n",
    "\t# Crop the image to remove irrelevant parts (e.g., score and borders)\n",
    "\tcropped_image = image[34:-16, :]\n",
    "\t# Downsample the image by taking every second pixel (both rows and columns)\n",
    "\tdownsampled_image = cropped_image[::2, ::2]\n",
    "\t# Subtract the background color\n",
    "\tadjusted_image = downsampled_image - bkg_color\n",
    "\t# Convert to grayscale by taking the mean across the color channels\n",
    "\tgrayscale_image = np.mean(adjusted_image, axis=-1)\n",
    "\t# Normalize pixel values to the range [0, 1]\n",
    "\tnormalized_image = grayscale_image / 255.0\n",
    "\n",
    "\treturn normalized_image\n",
    "\n",
    "\n",
    "def preprocess_batch(images, bkg_color=np.array([144, 72, 17])):\n",
    "\t\"\"\"\n",
    "\tConvert outputs of ParallelEnv to inputs for tensor processing.\n",
    "\n",
    "\tArgs:\n",
    "\t\timages (list or np.ndarray): Batch of input images (game frames).\n",
    "\t\tbkg_color (np.ndarray): The RGB background color to subtract.\n",
    "\t\tdevice (str): The device to which the tensor will be moved (e.g., \"cpu\" or \"cuda\").\n",
    "\n",
    "\tReturns:\n",
    "\t\ttorch.Tensor: The processed batch of images as a tensor, normalized to [0, 1].\n",
    "\t\"\"\"\n",
    "\t# Ensure images are in a NumPy array\n",
    "\t# shape: (time_steps, height, width, channel)\n",
    "\tbatch_images = np.asarray(images)\n",
    "\n",
    "\t# If the input has less than 5 dimensions, expand the dimensions\n",
    "\t# shape: (time_steps, batch, height, width, channels)\n",
    "\tif len(batch_images.shape) < 5:\n",
    "\t\tbatch_images = np.expand_dims(batch_images, 1)\n",
    "\n",
    "\t# Process each image in the batch using logic from the preprocess function\n",
    "\t# shape: (time_steps, batch, height, width, channels)\n",
    "\tcropped_images = batch_images[:, :, 34:-16, :, :]  # Crop the images\n",
    "\tdownsampled_images = cropped_images[:, :, ::2, ::2, :]  # Downsample the images\n",
    "\tadjusted_images = downsampled_images - bkg_color  # Subtract the background color\n",
    "\t\n",
    "\t# Convert to grayscale and normalize pixel values to [0, 1]\n",
    "\t# shape: (time_steps, batch, height, width)\n",
    "\tgrayscale_images = np.mean(adjusted_images, axis=-1)  \n",
    "\tnormalized_images = grayscale_images / 255.0\n",
    "\n",
    "\t# Rearrange the batch dimension to match the expected input format\n",
    "\t# shape: (batch, time_steps, height, width) or in other way\n",
    "\t#        (batch, channel, height, width)\n",
    "\tbatch_input = torch.from_numpy(normalized_images).float()\n",
    "\tbatch_input = batch_input.permute(1, 0, 2, 3)\n",
    "\treturn batch_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Frame Shape: (210, 160, 3)\n",
      "Processed Frame Shape: (80, 80)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test: get 20-th frame\n",
    "env.reset()\n",
    "for _ in range(20):\n",
    "\taction = 1 # fire\n",
    "\tframe, *_ = env.step(action)\n",
    "\n",
    "processed_frame = preprocess(frame)\n",
    "\n",
    "display_frame(frame, processed_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Shared Architecture\n",
    "\n",
    "In this implementation, we define both the Actor and Critic networks, which share a common feature extraction backbone. This design is inspired by the architecture of the [DQN](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf), where convolutional layers are used to process raw pixel inputs for reinforcement learning tasks. However, we adapt and modify the network architecture to suit the Actor-Critic framework and the specific requirements of our problem.\n",
    "\n",
    "#### Action-Value Network in DQN\n",
    "In DQN, a single network is used to estimate the action-value function $Q(s, a)$, where $s$ represents the state and $a$ represents the action. The network processes raw pixel inputs through convolutional layers, followed by fully connected layers, to output a value for each possible action.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"./images/dqn-network.png\" alt=\"DQN Network Architecture\" width=\"50%\">\n",
    "</div>\n",
    "\n",
    "#### Shared Feature Extraction Backbone for Actor and Critic\n",
    "In the Actor-Critic framework, we require two separate outputs:\n",
    "1. **Actor**: Outputs a probability distribution over actions (policy).\n",
    "2. **Critic**: Outputs a scalar value representing the estimated value of the current state.\n",
    "\n",
    "To achieve this, we use a shared feature extraction backbone consisting of convolutional layers and an intermediate fully connected layer. This shared backbone processes the raw pixel inputs (stacked frames) and extracts meaningful features that are used by both the Actor and Critic networks. \n",
    "\n",
    "This shared architecture offers several advantages:\n",
    "- **Reduced Computational Redundancy**: Both networks use the same extracted features, avoiding duplicate computation.\n",
    "- **Improved Learning Efficiency**: Sharing features ensures that both networks benefit from the same learned representations, leading to better coordination between the Actor and Critic.\n",
    "- **Simplified Design**: A unified backbone makes the architecture modular and easier to manage.\n",
    "\n",
    "#### Architecture Overview\n",
    "The shared feature extraction backbone consists of:\n",
    "- **Convolutional Layers**: These layers reduce the spatial dimensions of the input while capturing spatial and temporal dependencies in the stacked frames.\n",
    "- **Intermediate Fully Connected Layer**: This layer transforms the extracted spatial features into a compact representation suitable for the Actor and Critic outputs.\n",
    "\n",
    "The Actor and Critic networks then use this shared representation to produce their respective outputs:\n",
    "- **Actor**: A fully connected layer maps the shared representation to action logits, which are converted into probabilities using a softmax or categorical distribution.\n",
    "- **Critic**: A fully connected layer maps the shared representation to a single scalar value representing the state value $V(s)$.\n",
    "\n",
    "This modular design ensures that the Actor and Critic networks are tightly coupled and learn from the same extracted features, improving the stability and efficiency of training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Define Actor Network\n",
    "\n",
    "- Actor Network\n",
    "\t- input is the stack of two different frames (which captures the movement)\n",
    "\t- output is number of actions, each neuron represent probability of eachf action, such as,  $P_{\\rm right}$, $P_{\\rm left}$\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "\t\t<img src=\"./images/policy-network.png\" alt=\"Mountain Car Environment\" width=\"60%\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedFeatureExtractor(nn.Module):\n",
    "\t\"\"\"\n",
    "\tShared feature extraction network for both Actor and Critic.\n",
    "\t\"\"\"\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(SharedFeatureExtractor, self).__init__()\n",
    "\t\t\n",
    "\t\t# Convolutional layers\n",
    "\t\tself.conv1 = nn.Conv2d(2, 32, kernel_size=4, stride=4)  # 80x80x2 -> 20x20x32\n",
    "\t\tself.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)  # 20x20x32 -> 9x9x64\n",
    "\t\tself.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)  # 9x9x64 -> 7x7x64\n",
    "\t\t\n",
    "\t\t# Flattened size after convolutional layers\n",
    "\t\tself.size = 7 * 7 * 64\n",
    "\n",
    "\t\t# Fully connected layer for feature extraction\n",
    "\t\tself.fc = nn.Linear(self.size, 128)  # 7x7x64 -> 128\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t# Pass through convolutional layers with ReLU activation\n",
    "\t\tx = F.relu(self.conv1(x))\n",
    "\t\tx = F.relu(self.conv2(x))\n",
    "\t\tx = F.relu(self.conv3(x))\n",
    "\t\t\n",
    "\t\t# Flatten the tensor\n",
    "\t\tx = x.view(-1, self.size)\n",
    "\t\t\n",
    "\t\t# Pass through the fully connected layer\n",
    "\t\tx = F.relu(self.fc(x))\n",
    "\t\t\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network:\n",
      " Actor(\n",
      "  (shared_extractor): SharedFeatureExtractor(\n",
      "    (conv1): Conv2d(2, 32, kernel_size=(4, 4), stride=(4, 4))\n",
      "    (conv2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "    (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (fc): Linear(in_features=3136, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc_actor): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "Testing forward pass...\n",
      "Output logits from forward pass: tensor([[-0.0426,  0.1012]], device='mps:0', grad_fn=<LinearBackward0>)\n",
      "\n",
      "Testing select_action...\n",
      "Selected action (inference mode): 1\n",
      "\n",
      "Testing get_action_probs...\n",
      "Log probabilities of the actions: tensor([-0.7676], device='mps:0', grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "class Actor(nn.Module):\n",
    "\n",
    "\tdef __init__(self, shared_extractor):\n",
    "\t\tsuper(Actor, self).__init__()\n",
    "\t\t\n",
    "\t\tself.RIGHTFIRE = Action.RIGHTFIRE.value\n",
    "\t\tself.LEFTFIRE = Action.LEFTFIRE.value\n",
    "\n",
    "\t\tself.shared_extractor = shared_extractor\n",
    "\t\tself.fc_actor = nn.Linear(128, 2)  # Output layer for action probabilities\n",
    "\t\t\n",
    "\tdef forward(self, x):\n",
    "\t\t# Extract shared features\n",
    "\t\tfeatures = self.shared_extractor(x)\n",
    "\t\t\n",
    "\t\t# Get action logits\n",
    "\t\tlogits = self.fc_actor(features)\n",
    "\t\treturn logits\n",
    "\n",
    "\t@torch.no_grad()\n",
    "\tdef select_action(self, frames, mode='inference'):\n",
    "\t\t\"\"\"\n",
    "\t\tSelect actions based on policy for either inference or trajectory collection.\n",
    "\t\t\n",
    "\t\tArgs:\n",
    "\t\t\tframes: Tuple of (frame1, frame2) or preprocessed tensor\n",
    "\t\t\tmode: Either 'inference' for single action or 'collect' for trajectory collection\n",
    "\t\t\t\n",
    "\t\tReturns:\n",
    "\t\t\tFor mode='inference': single action value\n",
    "\t\t\tFor mode='collect': tuple of (states, actions, action_probs)\n",
    "\t\t\"\"\"\n",
    "\t\t# Ensure frames are on the correct device\n",
    "\t\tif isinstance(frames, tuple):\n",
    "\t\t\tstates = preprocess_batch(frames).to(next(self.parameters()).device)\n",
    "\t\telse:\n",
    "\t\t\tstates = frames.to(next(self.parameters()).device)\n",
    "\t\t\n",
    "\t\t# Get action probabilities\n",
    "\t\tlogits = self(states)\n",
    "\t\tdist = torch.distributions.Categorical(logits=logits)\n",
    "\t\t\n",
    "\t\tif mode == 'inference':\n",
    "\t\t\t# Single instance inference\n",
    "\t\t\taction = dist.sample().item()\n",
    "\t\t\treturn action\n",
    "\n",
    "\t\telif mode == 'collect':            \n",
    "\t\t\t# Select actions for Batch trajectory\n",
    "\t\t\tactions = dist.sample()\n",
    "\t\t\t\n",
    "\t\t\t# Calculate action probabilities\n",
    "\t\t\taction_probs = dist.log_prob(actions)\n",
    "\t\t\t\n",
    "\t\t\treturn states, actions, action_probs\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(f\"Unknown mode: {mode}. Use 'inference' or 'collect'\")\n",
    "\n",
    "\tdef get_action_probs(self, states, actions):\n",
    "\t\t\"\"\"\n",
    "\t\tGet probabilities for given states and actions.\n",
    "\t\tUseful for calculating policy gradients.\n",
    "\t\t\n",
    "\t\tArgs:\n",
    "\t\t\tstates: Preprocessed state tensor\n",
    "\t\t\tactions: Tensor of actions taken\n",
    "\t\t\t\n",
    "\t\tReturns:\n",
    "\t\t\tTensor of action probabilities\n",
    "\t\t\"\"\"\n",
    "\t\tlogits = self(states)\n",
    "\t\tdist = torch.distributions.Categorical(logits=logits)\n",
    "\t\taction_probs = dist.log_prob(actions)\n",
    "\n",
    "\t\treturn action_probs\n",
    "\t\t\n",
    "shared_extractor = SharedFeatureExtractor()\n",
    "actor = Actor(shared_extractor).to(device)\n",
    "print(\"Network:\\n\", actor)\n",
    "\n",
    "# Test the forward function\n",
    "print(\"Testing forward pass...\")\n",
    "dummy_input = torch.randn(1, 2, 80, 80).to(device)\n",
    "logits = actor(dummy_input)\n",
    "print(f\"Output logits from forward pass: {logits}\")\n",
    "\n",
    "# Test the select_action function\n",
    "print(\"\\nTesting select_action...\")\n",
    "action = actor.select_action(dummy_input, mode='inference')\n",
    "print(f\"Selected action (inference mode): {action}\")\n",
    "\n",
    "# Test the get_action_probs function\n",
    "print(\"\\nTesting get_action_probs...\")\n",
    "actions = torch.tensor([0]).to(device)  # Example action tensor (assuming action space is [0, 1])\n",
    "action_probs = actor.get_action_probs(dummy_input, actions)\n",
    "print(f\"Log probabilities of the actions: {action_probs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Define Critic Network\n",
    "\n",
    "- **Purpose**: The Critic network is used to estimate the value of a given state, which is a scalar representing the expected cumulative reward starting from that state. It helps in guiding the Actor's updates during training by providing a baseline to calculate the advantage function.\n",
    "\n",
    "- **Input**: The input to the Critic network is a stack of two different frames (just like the Policy network). These frames capture the movement in the environment to provide temporal information.\n",
    "\n",
    "- **Output**: The output of the Critic network is a single scalar value, $V(s)$, which represents the value of the input state $s$.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"./images/value-network.png\" alt=\"Critic Network Diagram\" width=\"60%\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critic output value: tensor([[0.0095]], device='mps:0', grad_fn=<LinearBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class Critic(nn.Module):\n",
    "    \"\"\"\n",
    "    Critic network for value estimation.\n",
    "    \"\"\"\n",
    "    def __init__(self, shared_extractor):\n",
    "        super(Critic, self).__init__()\n",
    "        self.shared_extractor = shared_extractor\n",
    "        self.fc_critic = nn.Linear(128, 1)  # Output layer for state value\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract shared features\n",
    "        features = self.shared_extractor(x)\n",
    "        \n",
    "        # Get state value\n",
    "        value = self.fc_critic(features)\n",
    "        return value\n",
    "\n",
    "\n",
    "# Instantiate shared feature extractor\n",
    "shared_extractor = SharedFeatureExtractor()\n",
    "\n",
    "# Instantiate Critic network\n",
    "critic = Critic(shared_extractor).to(device)\n",
    "\n",
    "# Test the Critic network\n",
    "dummy_input = torch.randn(1, 2, 80, 80).to(device)\n",
    "value = critic(dummy_input)\n",
    "print(f\"Critic output value: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
